# 5.1 - Intro to ML monitoring

## Key Takeaways

* The video covers the basics of monitoring machine learning models in production environments
* It discusses the importance of monitoring and the metrics used to measure performance and quality of data
* It also explores reusing existing monitoring architecture for machine learning models and introduces the concept of batch monitoring pipelines
* The video aims to provide a good understanding of how to monitor machine learning models in production environments to ensure optimal performance.


## Introduction to monitoring machine learning models in production

* Machine learning models can degrade in performance over time.
* Monitoring machine learning models is important to ensure they continue to perform well.
* There are four groups of metrics to monitor:
  *  Service health: metrics that measure the health of the service that is running the model
  *  Model performance: metrics that measure the accuracy of the model
  *  Data quality: metrics that measure the quality of the data that the model is being used on
  *  Data drift: metrics that measure how the data has changed over time


## Reusing existing monitoring architecture for machine learning

* If you already have a monitoring architecture in place, you can reuse it for your machine learning models.
* If you don't have a monitoring architecture in place, you can start by using a BI tool like Tableau or Looker.


## Batch and online serving models

* Some metrics can only be calculated in batch mode, while others can be calculated in real time.
* For online models, you can use window functions to calculate metrics in batch.


## Batch monitoring pipeline for machine learning models

* A batch monitoring pipeline is a pipeline that works in batch mode to calculate metrics for machine learning models.
* The pipeline reads prediction logs, analyzes them, calculates metrics, and stores the metrics in a database.
* The metrics are then used to create a dashboard.


## Monitoring scheme

* The monitoring scheme is a general scheme that can be used for both batch and online models.
* The scheme consists of the following steps:
  * Simulate production usage of the service and generate logs.
  * Use Prefect to implement monitoring jobs.
  * Use Evidently to calculate metrics.
  * Load metrics into a Postgresql database.
  * Use Grafana to create a dashboard.
